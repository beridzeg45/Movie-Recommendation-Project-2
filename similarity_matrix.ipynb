{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns=100\n",
    "import kaggle\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "path=r\"C:\\Users\\berid\\python\\yts mx project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "yts_df=pd.read_csv(os.path.join(path,'scraped_data','cleaned_yts_movies_df.csv'))\n",
    "letterboxd_df=pd.read_csv(os.path.join(path,'scraped_data','cleaned_letterboxd_movies_df.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### merging dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "letterboxd_df=letterboxd_df.dropna(subset='IMDB_LINK')\n",
    "letterboxd_df['IMDB_LINK']=letterboxd_df['IMDB_LINK'].str.replace('http','https')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=yts_df.merge(letterboxd_df,how='left',on='IMDB_LINK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GENRES_x']=df['GENRES_x']+'|'\n",
    "df['DIRECTOR_x']=df['DIRECTOR_x']+'|'\n",
    "df['BIGRAMS_TAGS_x']=df['BIGRAMS_TAGS_x']+'|'\n",
    "df['DIRECTOR_y']=df['DIRECTOR_y']+'|'\n",
    "df['BIGRAMS_TAGS_y']=df['BIGRAMS_TAGS_y']+'|'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### applying weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags_list=[]\n",
    "for a,b,c,d,e,f,g,h in zip(df['GENRES_x'], df['DIRECTOR_x'], df['TAGS_x'], df['BIGRAMS_TAGS_x'], df['GENRES_y'], df['DIRECTOR_y'], df['TAGS_y'], df['BIGRAMS_TAGS_y']):\n",
    "    all_tags=str(a)*12+str(b)*5+str(c)*3+str(d)*1+str(e)*1+str(f)*5+str(g)*10+str(h)*1\n",
    "\n",
    "    all_tags_list.append(all_tags)\n",
    "\n",
    "df['ALL_TAGS']=all_tags_list\n",
    "df['ALL_TAGS']=df['ALL_TAGS'].apply(lambda x:x.replace('None','').replace('nan','').replace('Show Allâ€¦','|').replace('||','|').replace('||','|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['IMDB_LINK','POSTER','TITLE_x','YEAR_x','GENRES_x','DIRECTOR_x','IMDB_RATING','IMDB_RATING_COUNT','ALL_TAGS']]\n",
    "df.columns=df.columns.str.replace('_x','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### create similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berid\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\feature_extraction\\text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split('|'), stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df['ALL_TAGS'])\n",
    "\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "num_parts = 20\n",
    "array_parts = np.array_split(similarity_matrix, num_parts)\n",
    "\n",
    "for i, part in enumerate(array_parts):\n",
    "    with open(os.path.join(path,'scraped_data','similarities_matrix',f'array_part_{i}.pkl'), \"wb\") as f:\n",
    "        pickle.dump(part, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
